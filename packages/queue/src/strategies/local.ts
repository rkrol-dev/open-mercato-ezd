import fs from 'node:fs'
import path from 'node:path'
import crypto from 'node:crypto'
import type { Queue, QueuedJob, JobHandler, LocalQueueOptions, ProcessOptions, ProcessResult } from '../types'

type LocalState = {
  lastProcessedId?: string
  completedCount?: number
  failedCount?: number
}

type StoredJob<T> = QueuedJob<T>

/** Default polling interval in milliseconds */
const DEFAULT_POLL_INTERVAL = 1000
const DEFAULT_LOCAL_QUEUE_BASE_DIR = '.mercato/queue'

/**
 * Creates a file-based local queue.
 *
 * Jobs are stored in JSON files within a directory structure:
 * - `.mercato/queue/<name>/queue.json` - Array of queued jobs
 * - `.mercato/queue/<name>/state.json` - Processing state (last processed ID)
 *
 * **Limitations:**
 * - Jobs are processed sequentially (concurrency option is for logging/compatibility only)
 * - Not suitable for production or multi-process environments
 * - No retry mechanism for failed jobs
 *
 * @template T - The payload type for jobs
 * @param name - Queue name (used for directory naming)
 * @param options - Local queue options
 */
export function createLocalQueue<T = unknown>(
  name: string,
  options?: LocalQueueOptions
): Queue<T> {
  const nodeProcess = (globalThis as typeof globalThis & { process?: NodeJS.Process }).process
  const queueBaseDirFromEnv = nodeProcess?.env?.QUEUE_BASE_DIR
  const baseDir = options?.baseDir
    ?? path.resolve(queueBaseDirFromEnv || DEFAULT_LOCAL_QUEUE_BASE_DIR)
  const queueDir = path.join(baseDir, name)
  const queueFile = path.join(queueDir, 'queue.json')
  const stateFile = path.join(queueDir, 'state.json')
  // Note: concurrency is stored for logging/compatibility but jobs are processed sequentially
  const concurrency = options?.concurrency ?? 1
  const pollInterval = options?.pollInterval ?? DEFAULT_POLL_INTERVAL

  // Worker state for continuous polling
  let pollingTimer: ReturnType<typeof setInterval> | null = null
  let isProcessing = false
  let activeHandler: JobHandler<T> | null = null

  // -------------------------------------------------------------------------
  // File Operations
  // -------------------------------------------------------------------------

  function ensureDir(): void {
    // Use atomic operations to handle race conditions
    try {
      fs.mkdirSync(queueDir, { recursive: true })
    } catch (e: unknown) {
      const error = e as NodeJS.ErrnoException
      if (error.code !== 'EEXIST') throw error
    }

    // Initialize queue file with exclusive create flag
    try {
      fs.writeFileSync(queueFile, '[]', { encoding: 'utf8', flag: 'wx' })
    } catch (e: unknown) {
      const error = e as NodeJS.ErrnoException
      if (error.code !== 'EEXIST') throw error
    }

    // Initialize state file with exclusive create flag
    try {
      fs.writeFileSync(stateFile, '{}', { encoding: 'utf8', flag: 'wx' })
    } catch (e: unknown) {
      const error = e as NodeJS.ErrnoException
      if (error.code !== 'EEXIST') throw error
    }
  }

  function readQueue(): StoredJob<T>[] {
    ensureDir()
    try {
      const content = fs.readFileSync(queueFile, 'utf8')
      return JSON.parse(content) as StoredJob<T>[]
    } catch (error: unknown) {
      const e = error as NodeJS.ErrnoException
      if (e.code === 'ENOENT') {
        return []
      }
      console.error(`[queue:${name}] Failed to read queue file:`, e.message)
      throw new Error(`Queue file corrupted or unreadable: ${e.message}`)
    }
  }

  function writeQueue(jobs: StoredJob<T>[]): void {
    ensureDir()
    fs.writeFileSync(queueFile, JSON.stringify(jobs, null, 2), 'utf8')
  }

  function readState(): LocalState {
    ensureDir()
    try {
      const content = fs.readFileSync(stateFile, 'utf8')
      return JSON.parse(content) as LocalState
    } catch {
      return {}
    }
  }

  function writeState(state: LocalState): void {
    ensureDir()
    fs.writeFileSync(stateFile, JSON.stringify(state, null, 2), 'utf8')
  }

  function generateId(): string {
    return crypto.randomUUID()
  }

  // -------------------------------------------------------------------------
  // Queue Implementation
  // -------------------------------------------------------------------------

  async function enqueue(data: T): Promise<string> {
    const jobs = readQueue()
    const job: StoredJob<T> = {
      id: generateId(),
      payload: data,
      createdAt: new Date().toISOString(),
    }
    jobs.push(job)
    writeQueue(jobs)
    return job.id
  }

  /**
   * Process pending jobs in a single batch (internal helper).
   */
  async function processBatch(
    handler: JobHandler<T>,
    options?: ProcessOptions
  ): Promise<ProcessResult> {
    const state = readState()
    const jobs = readQueue()

    // Find jobs that haven't been processed yet
    const lastProcessedIndex = state.lastProcessedId
      ? jobs.findIndex((j) => j.id === state.lastProcessedId)
      : -1

    const pendingJobs = jobs.slice(lastProcessedIndex + 1)
    const jobsToProcess = options?.limit
      ? pendingJobs.slice(0, options.limit)
      : pendingJobs

    let processed = 0
    let failed = 0
    let lastJobId: string | undefined
    const jobIdsToRemove = new Set<string>()

    for (const job of jobsToProcess) {
      try {
        await Promise.resolve(
          handler(job, {
            jobId: job.id,
            attemptNumber: 1,
            queueName: name,
          })
        )
        processed++
        lastJobId = job.id
        jobIdsToRemove.add(job.id)
        console.log(`[queue:${name}] Job ${job.id} completed`)
      } catch (error) {
        console.error(`[queue:${name}] Job ${job.id} failed:`, error)
        failed++
        lastJobId = job.id
        jobIdsToRemove.add(job.id) // Remove failed jobs too (matching async strategy)
      }
    }

    // Remove processed jobs from queue (matching async removeOnComplete behavior)
    if (jobIdsToRemove.size > 0) {
      const updatedJobs = jobs.filter((j) => !jobIdsToRemove.has(j.id))
      writeQueue(updatedJobs)

      // Update state with running counts
      const newState: LocalState = {
        lastProcessedId: lastJobId,
        completedCount: (state.completedCount ?? 0) + processed,
        failedCount: (state.failedCount ?? 0) + failed,
      }
      writeState(newState)
    }

    return { processed, failed, lastJobId }
  }

  /**
   * Poll for and process new jobs.
   */
  async function pollAndProcess(): Promise<void> {
    // Skip if already processing to avoid concurrent file access
    if (isProcessing || !activeHandler) return

    isProcessing = true
    try {
      await processBatch(activeHandler)
    } catch (error) {
      console.error(`[queue:${name}] Polling error:`, error)
    } finally {
      isProcessing = false
    }
  }

  async function process(
    handler: JobHandler<T>,
    options?: ProcessOptions
  ): Promise<ProcessResult> {
    // If limit is specified, do a single batch (backward compatibility)
    if (options?.limit) {
      return processBatch(handler, options)
    }

    // Start continuous polling mode (like BullMQ Worker)
    activeHandler = handler

    // Process any pending jobs immediately
    await processBatch(handler)

    // Start polling interval for new jobs
    pollingTimer = setInterval(() => {
      pollAndProcess().catch((err) => {
        console.error(`[queue:${name}] Poll cycle error:`, err)
      })
    }, pollInterval)

    console.log(`[queue:${name}] Worker started with concurrency ${concurrency}`)

    // Return sentinel value indicating continuous worker mode (like async strategy)
    return { processed: -1, failed: -1, lastJobId: undefined }
  }

  async function clear(): Promise<{ removed: number }> {
    const jobs = readQueue()
    const removed = jobs.length
    writeQueue([])
    // Reset state but preserve counts for historical tracking
    const state = readState()
    writeState({
      completedCount: state.completedCount,
      failedCount: state.failedCount,
    })
    return { removed }
  }

  async function close(): Promise<void> {
    // Stop polling timer
    if (pollingTimer) {
      clearInterval(pollingTimer)
      pollingTimer = null
    }
    activeHandler = null

    // Wait for any in-progress processing to complete (with timeout)
    const SHUTDOWN_TIMEOUT = 5000
    const startTime = Date.now()

    while (isProcessing) {
      if (Date.now() - startTime > SHUTDOWN_TIMEOUT) {
        console.warn(`[queue:${name}] Force closing after ${SHUTDOWN_TIMEOUT}ms timeout`)
        break
      }
      await new Promise((resolve) => setTimeout(resolve, 50))
    }
  }

  async function getJobCounts(): Promise<{
    waiting: number
    active: number
    completed: number
    failed: number
  }> {
    const state = readState()
    const jobs = readQueue()

    return {
      waiting: jobs.length, // All jobs in queue are waiting (processed ones are removed)
      active: 0, // Local strategy doesn't track active jobs
      completed: state.completedCount ?? 0,
      failed: state.failedCount ?? 0,
    }
  }

  return {
    name,
    strategy: 'local',
    enqueue,
    process,
    clear,
    close,
    getJobCounts,
  }
}
